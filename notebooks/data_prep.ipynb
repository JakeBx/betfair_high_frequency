{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm as pbar\n",
    "from utils import tick_delta, dollars_to_ticks\n",
    "import pickle as p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* [x] Include time to market in final set\n",
    "* [x] Include normalisation of the lay volume\n",
    "* [x] Include the mid price in ticks\n",
    "* Update code to include limits (i.e., only include 10 races)\n",
    "* [x] Batch the saving of files into multiple files (Reduce the memory burden)\n",
    "* [x] Include some simple MAs for linear models\n",
    "* Update movement function on win type (batl moving to batb-5 for W, batb moving to batl+5)\n",
    "* [x] Exclude the fucking index on the saving of files\n",
    "* Move dataframe transformation into seperate file\n",
    "* Resample to 1 second\n",
    "\n",
    "Bot Updates\n",
    "\n",
    "* The bot should trade only down\n",
    "* The bot should enter a position according to optimisation over a loss function to set the threshold\n",
    "* The bot should exit the position according to another exit threshold\n",
    "* Implement the cashout function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = dt.now().strftime('%m%d')\n",
    "year = '2019'\n",
    "month = 'Sep'\n",
    "stem_path = '/Users/jake/Downloads/PRO 2/2019/Sep/'\n",
    "gcloud_path = 'gs://h2o_temp/dev_sets/'\n",
    "# n_limit = 10 # None for all files in set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_dict():\n",
    "    return defaultdict(int)\n",
    "\n",
    "def double_d():\n",
    "    return defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markets(entries):\n",
    "    market_defs = []\n",
    "    market_defs_ids = []\n",
    "    for entry in entries:\n",
    "        for rc in entry['mc']:\n",
    "            if 'marketDefinition' in rc.keys():\n",
    "                market_defs.append(rc['marketDefinition'])\n",
    "                market_defs_ids.append(rc['id'])\n",
    "    \n",
    "    mrkt_def = pd.DataFrame(market_defs)\n",
    "    mrkt_def['market_id'] = market_defs_ids\n",
    "    \n",
    "    return mrkt_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entries(entries):\n",
    "    batl = []\n",
    "    batb = []\n",
    "    batl_v = {}\n",
    "    batb_v = {}\n",
    "    for n in range(6):\n",
    "        batl_v[n] = []\n",
    "        batb_v[n] = []\n",
    "            \n",
    "    mrkts = []\n",
    "    times = []\n",
    "    sids = []\n",
    "    tot_vols = []\n",
    "    in_play = []\n",
    "    mean_trd = []\n",
    "    mrkt_inplay = {}\n",
    "    tvs = defaultdict(int_dict)\n",
    "    back_ladder = defaultdict(double_d)\n",
    "    lay_ladder = defaultdict(double_d)\n",
    "    trd_ladder = defaultdict(int_dict)\n",
    "\n",
    "    market_defs = []\n",
    "    market_defs_ids = []\n",
    "    \n",
    "    for entry in entries: # should be map\n",
    "            ts = entry['pt']\n",
    "            change_sids = []\n",
    "            change_mids = []\n",
    "            for rc in entry['mc']:\n",
    "                if 'marketDefinition' in rc.keys():\n",
    "                    play_mid = rc['id']\n",
    "                    mrkt_inplay[play_mid] = rc['marketDefinition']['inPlay']\n",
    "                    market_defs. append(rc['marketDefinition'])\n",
    "                    market_defs_ids.append(rc['id'])\n",
    "                if 'rc' in rc.keys():\n",
    "                    mid = rc['id']\n",
    "                    for change in rc['rc']:\n",
    "                        sid = change['id']\n",
    "                        change_sids.append(sid)\n",
    "                        change_mids.append(mid)\n",
    "                        keys = change.keys()\n",
    "                        if 'atb' in keys:\n",
    "                            for prc, vol in change['atb']:\n",
    "                                back_ladder[mid][sid][prc] = vol\n",
    "                        if 'atl' in keys:\n",
    "                            for prc, vol in change['atl']:\n",
    "                                lay_ladder[mid][sid][prc] = vol\n",
    "#                         if 'tv' in keys:\n",
    "#                             tvs[mid][sid] = change['tv']\n",
    "                        if 'trd' in keys:\n",
    "                            for prc, vol in change['trd']:\n",
    "                                trd_ladder[sid][prc] += vol\n",
    "                        # TODO: Add in trade history: if 'trd' in keys:\n",
    "            for sid, mid in zip(change_sids, change_mids):\n",
    "                cur_batl = min([1000] + [k for k, v in lay_ladder[mid][sid].items() if v > 1])\n",
    "                cur_batb = max([0] + [k for k, v in back_ladder[mid][sid].items() if v > 1])\n",
    "#                         cur_tv = tvs[mid][sid]\n",
    "                if cur_batl < 10 and cur_batb > 0:\n",
    "                    tot_vol = 0\n",
    "                    agg_vol = 0\n",
    "                    for p, v in trd_ladder[sid].items():\n",
    "                        agg_vol += float(p) * v\n",
    "                        tot_vol += v\n",
    "                    if tot_vol > 500:\n",
    "                        mean_price = agg_vol / tot_vol if tot_vol > 1 else 0\n",
    "                        mean_trd.append(mean_price)\n",
    "                        times.append(ts)\n",
    "                        sids.append(sid)\n",
    "                        mrkts.append(mid)\n",
    "                        batl.append(cur_batl)\n",
    "                        batb.append(cur_batb)\n",
    "                        for n in range(6):\n",
    "                            adj_batl = tick_delta(cur_batl, n)\n",
    "                            adj_batb = tick_delta(cur_batb, -n)\n",
    "                            if adj_batl in lay_ladder[mid][sid].keys():\n",
    "                                batl_v[n].append(lay_ladder[mid][sid][adj_batl])\n",
    "                            else:\n",
    "                                batl_v[n].append(None)\n",
    "                            if adj_batb in back_ladder[mid][sid].keys():\n",
    "                                batb_v[n].append(back_ladder[mid][sid][adj_batb])\n",
    "                            else:\n",
    "                                batb_v[n].append(None)\n",
    "                        tot_vols.append(tot_vol)\n",
    "                        in_play.append(mrkt_inplay[mid])\n",
    "\n",
    "    df = pd.DataFrame({'timestamp': times, \n",
    "               'market_id': mrkts, \n",
    "               'sid': sids, \n",
    "               'batl': batl, \n",
    "               'batb': batb, \n",
    "               'batl_v': batl_v[0], \n",
    "               'batb_v': batb_v[0],\n",
    "               'batl_v_1': batl_v[1], \n",
    "               'batb_v_1': batb_v[1], \n",
    "               'batl_v_2': batl_v[2], \n",
    "               'batb_v_2': batb_v[2], \n",
    "               'batl_v_3': batl_v[3], \n",
    "               'batb_v_3': batb_v[3], \n",
    "               'batl_v_4': batl_v[4], \n",
    "               'batb_v_4': batb_v[4], \n",
    "               'batl_v_5': batl_v[5], \n",
    "               'batb_v_5': batb_v[5], \n",
    "               'tot_vol': tot_vols,\n",
    "                'mean_trd': mean_trd,\n",
    "                'in_play': in_play})\n",
    "    \n",
    "#     df.timestamp = df.timestamp // 1000\n",
    "#     df.timestamp = df.timestamp.apply(dt.fromtimestamp)\n",
    "#     df.timestamp = pd.to_datetime(df.timestamp)\n",
    "    \n",
    "    mrkt_def = pd.DataFrame(market_defs)\n",
    "    mrkt_def['market_id'] = market_defs_ids\n",
    "#     keep_cols = ['market_id', 'eventId', 'eventTypeId', 'numberOfWinners','bettingType', 'marketType', 'marketTime', 'name', 'eventName']\n",
    "#     mrkt_def = mrkt_def[keep_cols]\n",
    "#     mrkt_def.drop_duplicates(inplace=True)\n",
    "#     mrkt_def = mrkt_def[(mrkt_def.marketType=='WIN')]\n",
    "#     mrkt_def.marketTime = pd.to_datetime(mrkt_def.marketTime)\n",
    "#     mrkt_def.marketTime += np.timedelta64(10,'h')\n",
    "    \n",
    "    return df, mrkt_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pos(row):\n",
    "    val = row.mid_ticks + 5\n",
    "    idx = np.argwhere(idxs[row.sid] == row.inc_idx).flatten()[0]\n",
    "    val = np.argmax(vals[row.sid][idx:] >= val)\n",
    "    return val\n",
    "\n",
    "def find_neg(row):\n",
    "    val = row.mid_ticks - 5\n",
    "    idx = np.argwhere(idxs[row.sid] == row.inc_idx).flatten()[0]\n",
    "    val = np.argmax(vals[row.sid][idx:] <= val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [x for x in os.listdir(stem_path) if len(x) <= 2]#[:2] # limit to first two days\n",
    "final_paths = {}\n",
    "for day in days:\n",
    "    for fld in os.listdir(os.path.join(stem_path, day)):\n",
    "        try:\n",
    "            int(fld) # shit house validity check\n",
    "            final_paths[fld] = os.path.join(stem_path, day, fld, fld+'.bz2')\n",
    "        except:\n",
    "            print(f'failed on {fld}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = len(final_paths.keys())\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = f'../data/prepared/{run_id}_{year}_{month}'\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "keep_cols = ['market_id', 'eventId', 'eventTypeId', 'numberOfWinners','bettingType', 'marketType', 'marketTime', 'name', 'eventName']\n",
    "\n",
    "intermediate_cols = ['timestamp', 'test_starttime', 'market_id', 'sid', 'batl', 'batb', 'batl_v', 'batb_v',\n",
    "       'batl_v_1', 'batb_v_1', 'batl_v_2', 'batb_v_2', 'batl_v_3', 'batb_v_3',\n",
    "       'batl_v_4', 'batb_v_4', 'batl_v_5', 'batb_v_5', 'tot_vol', 'mean_trd']\n",
    "\n",
    "lay_vol_cols = ['batl_v', 'batl_v_1', 'batl_v_2', 'batl_v_3', 'batl_v_4', 'batl_v_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_cols = ['batl_ticks', 'batl_v', 'batb_v',\n",
    "       'batl_v_1', 'batb_v_1', 'batl_v_2', 'batb_v_2', 'batl_v_3', 'batb_v_3',\n",
    "       'batl_v_4', 'batb_v_4', 'batl_v_5', 'batb_v_5', 'ticks_from_mean']\n",
    "ma_periods = [5, 10, 50]\n",
    "\n",
    "ma_features = []\n",
    "for c, l in product(ma_cols, ma_periods):\n",
    "    ma_features.append(f'{c}_ma_{l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['batl_ticks', 'time_to_markt', 'batl_v', 'batb_v',\n",
    "       'batl_v_1', 'batb_v_1', 'batl_v_2', 'batb_v_2', 'batl_v_3', 'batb_v_3',\n",
    "       'batl_v_4', 'batb_v_4', 'batl_v_5', 'batb_v_5', 'ticks_from_mean',\n",
    "       'spread', 'ticks_1', 'ticks_2', 'ticks_3', 'ticks_4',\n",
    "       'ticks_5', 'ticks_6', 'ticks_7', 'ticks_8', 'ticks_9', 'ticks_10',\n",
    "       'ticks_11', 'ticks_12', 'ticks_13', 'ticks_14', 'ticks_15', 'ticks_16',\n",
    "       'ticks_17', 'ticks_18', 'ticks_19', 'ticks_20', 'ticks_21', 'ticks_22',\n",
    "       'ticks_23', 'ticks_24', 'ticks_25', 'ticks_26', 'ticks_27', 'ticks_28',\n",
    "       'ticks_29', 'ticks_30', 'ticks_31', 'ticks_32', 'ticks_33', 'ticks_34',\n",
    "       'ticks_35', 'ticks_36', 'ticks_37', 'ticks_38', 'ticks_39', 'ticks_40',\n",
    "       'ticks_41', 'ticks_42', 'ticks_43', 'ticks_44', 'ticks_45', 'ticks_46',\n",
    "       'ticks_47', 'ticks_48', 'ticks_49']\n",
    "\n",
    "y_name = 'label'\n",
    "\n",
    "feature_cols.extend(ma_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bfdf6279834fedb9fa40b8f4538d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=288.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:46: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:52: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/Users/jake/miniconda3/envs/betfair/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed on 29475609, with exception: Cannot set a frame with no defined index and a value that cannot be converted to a Series\n",
      "Failed on 29453654, with exception: Cannot set a frame with no defined index and a value that cannot be converted to a Series\n",
      "Failed on 29425783, with exception: Cannot convert tz-naive timestamps, use tz_localize to localize\n",
      "Failed on 29466021, with exception: Cannot set a frame with no defined index and a value that cannot be converted to a Series\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Rename dfs thoughout to a single df and not get the overwrite on slice thing\n",
    "dfs = []\n",
    "defs = []\n",
    "for k, v in pbar(final_paths.items(), '', count):\n",
    "    try:\n",
    "        fn = v\n",
    "\n",
    "        entries = []\n",
    "        with bz2.open(fn, mode='r') as f:\n",
    "            for line in f.readlines():\n",
    "                entries.append(json.loads(line))\n",
    "\n",
    "        df, mrkt_def = parse_entries(entries)\n",
    "\n",
    "        df = df.groupby(['timestamp','market_id', 'sid']).last().reset_index()\n",
    "        df.timestamp = df.timestamp // 1000\n",
    "        df.timestamp = df.timestamp.apply(dt.fromtimestamp)\n",
    "        df.timestamp = pd.to_datetime(df.timestamp)\n",
    "\n",
    "        mrkt_def = mrkt_def[keep_cols]\n",
    "        mrkt_def.drop_duplicates(inplace=True)\n",
    "        mrkt_def = mrkt_def[(mrkt_def.marketType=='WIN')]\n",
    "        mrkt_def.marketTime = pd.to_datetime(mrkt_def.marketTime)\n",
    "        mrkt_def.marketTime += np.timedelta64(10,'h')\n",
    "\n",
    "        new_df = df.merge(mrkt_def, on='market_id', how='inner')\n",
    "        new_df['test_starttime'] = new_df.marketTime.dt.tz_convert(None)\n",
    "        new_df['test_recordtime'] = new_df.test_starttime - np.timedelta64(20,'m')\n",
    "        new_df = new_df[(new_df.timestamp < new_df.test_starttime) & (new_df.timestamp > new_df.test_recordtime)]\n",
    "        \n",
    "        df = new_df\n",
    "\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        df = df[intermediate_cols]\n",
    "\n",
    "        df['time_to_markt'] = df.test_starttime - df.timestamp\n",
    "        df['time_to_markt'] = df['time_to_markt'].astype(np.int) // 1000000000\n",
    "        df['mid'] = (df.batb + df.batl) / 2\n",
    "\n",
    "        for c in lay_vol_cols:\n",
    "            df[c] = df[c] * df.mid\n",
    "\n",
    "        price_cols = ['batl', 'batb', 'mean_trd', 'mid']\n",
    "        for c in price_cols:\n",
    "            df[f'{c}_ticks'] = df[c].apply(dollars_to_ticks)\n",
    "\n",
    "        df['spread'] = df.batl_ticks - df.batb_ticks\n",
    "\n",
    "        df['diff'] = df.groupby(['market_id', 'sid']).mid_ticks.diff().cumsum()\n",
    "\n",
    "        df['trade_cnt'] = 1\n",
    "        df['trade_cnt'] = df.groupby(['market_id', 'sid']).trade_cnt.cumsum()\n",
    "\n",
    "        vals = {}\n",
    "        idxs = {}\n",
    "        for sid in df.sid.unique():\n",
    "            vals[sid] = df[df.sid==sid].mid_ticks.values\n",
    "            idxs[sid] = df[df.sid==sid].index.values\n",
    "\n",
    "        df['inc_idx'] = df.index\n",
    "        df['pos_idx'] = df.apply(find_pos, axis=1)\n",
    "        df['neg_idx'] = df.apply(find_neg, axis=1)\n",
    "        df['label'] = df.pos_idx < df.neg_idx\n",
    "\n",
    "        for x in range(1, 50):\n",
    "            df[f'ticks_{x}'] = df.mid_ticks - df.groupby(['market_id', 'sid']).mid_ticks.shift(x)\n",
    "\n",
    "        df['ticks_from_mean'] = df.mid_ticks - df.mean_trd_ticks\n",
    "        for c, l in product(ma_cols, ma_periods):\n",
    "            df[f'{c}_ma_{l}'] = df[c].rolling(l).mean()\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        df[feature_cols + [y_name]].to_csv(os.path.join(dir_path, f'{k}.csv'), index=False)\n",
    "    except Exception as e:\n",
    "        print(f'Failed on {k}, with exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./../data/prepared/0106_2019_Sep/29443900.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29443974.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444059.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444042.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29443999.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444172.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446120.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447381.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444091.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448997.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448964.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446247.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448981.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444290.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29449274.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450286.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448984.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446250.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29444828.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29445998.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446268.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446023.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448996.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29446024.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447457.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447223.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447224.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447214.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29449020.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448889.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29448965.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29447247.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450293.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450302.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450294.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450303.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450304.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450305.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450432.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29450292.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451611.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451622.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451627.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451632.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451637.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451735.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451748.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451793.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451822.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451842.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451850.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451859.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29451865.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29452118.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29453672.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29453688.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29453704.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29453715.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454089.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454115.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454140.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454283.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454468.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29454479.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455078.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455090.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455195.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455197.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455213.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455451.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455454.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455472.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455474.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455486.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29455487.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29456224.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29457254.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29457257.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29457303.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29457488.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29457492.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29458152.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459072.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459096.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459275.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459276.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459345.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459386.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459407.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29459429.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460735.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460736.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460749.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460751.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460753.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460756.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460765.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29460922.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462242.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462243.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462249.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462260.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462261.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462286.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29462290.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464174.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464201.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464238.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464239.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464250.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464252.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464276.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464277.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464302.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464304.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464426.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464517.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29464548.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466005.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466017.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466028.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466031.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466035.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466047.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466068.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466091.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466127.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466142.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466216.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466419.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466431.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29466433.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467620.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467642.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467655.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467703.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467785.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467809.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467810.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29467822.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29468729.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29469915.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29469927.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29469940.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29470080.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29470186.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29470347.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29470614.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472194.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472213.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472265.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472271.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472365.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472848.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29472855.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473912.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473913.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473918.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473919.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473959.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29473984.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29474010.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29474155.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475587.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475588.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475600.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475630.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475760.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29475908.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29476274.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29476538.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478018.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478060.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478063.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478071.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478082.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478092.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478116.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478128.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478129.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478144.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478148.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478192.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478193.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29478221.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480038.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480046.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480048.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480063.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480111.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480227.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480283.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480373.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480375.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480553.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480556.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480557.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29480728.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29481985.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29481987.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29481989.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482003.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482007.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482228.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482253.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482406.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29482410.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29483078.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29483117.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29484743.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29484787.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29484802.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29484935.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29484936.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29485220.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29485276.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487042.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487044.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487059.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487095.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487238.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487282.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487396.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29487397.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488618.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488627.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488628.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488665.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488674.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488693.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488830.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29488871.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490667.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490763.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490786.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490805.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490809.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29490820.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29491126.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492777.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492831.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492847.csv [Content-Type=text/csv]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492863.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492904.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492935.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492940.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492986.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29492994.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493030.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493053.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493111.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493355.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493435.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493436.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29493437.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494856.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494870.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494885.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494889.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494891.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494892.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29494920.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29495041.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29495108.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29495344.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29496871.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29496876.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29496923.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29496979.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29496994.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497003.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497016.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497017.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497018.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497151.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29497152.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499282.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499311.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499316.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499733.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499738.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499798.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29499799.csv [Content-Type=text/csv]...\n",
      "Copying file://./../data/prepared/0106_2019_Sep/29500053.csv [Content-Type=text/csv]...\n",
      "| [284/284 files][  8.9 GiB/  8.9 GiB] 100% Done   2.3 MiB/s ETA 00:00:00       \n",
      "Operation completed over 284 objects/8.9 GiB.                                    \n"
     ]
    }
   ],
   "source": [
    "os.environ['new_path'] = dir_path\n",
    "os.environ['gcp_path'] = f'prepared/{run_id}_{year}_{month}'\n",
    "!gsutil -m cp -r ./$new_path/*.csv gs://temp_h2o/$gcp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_to_markt'].astype(np.int) // 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*60 + 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# defs = []\n",
    "# for k, v in pbar(final_paths.items(), '', count):\n",
    "#     fn = v\n",
    "\n",
    "#     entries = []\n",
    "#     with bz2.open(fn, mode='r') as f:\n",
    "#         for line in f.readlines():\n",
    "#             entries.append(json.loads(line))\n",
    "\n",
    "#     df, mrkt_def = parse_entries(entries)\n",
    "    \n",
    "    \n",
    "#     dfs.append(df)\n",
    "#     defs.append(mrkt_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "final_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "final_df = final_df.groupby(['timestamp','market_id', 'sid']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "final_df.timestamp = final_df.timestamp // 1000\n",
    "final_df.timestamp = final_df.timestamp.apply(dt.fromtimestamp)\n",
    "final_df.timestamp = pd.to_datetime(final_df.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defs_df = pd.concat(defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "defs_df = defs_df[keep_cols]\n",
    "defs_df.drop_duplicates(inplace=True)\n",
    "defs_df = defs_df[(defs_df.marketType=='WIN')]\n",
    "defs_df.marketTime = pd.to_datetime(defs_df.marketTime)\n",
    "defs_df.marketTime += np.timedelta64(10,'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = final_df.merge(defs_df, on='market_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['test_starttime'] = new_df.marketTime.dt.tz_convert(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['test_recordtime'] = new_df.test_starttime - np.timedelta64(20,'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[(new_df.timestamp < new_df.test_starttime) & (new_df.timestamp > new_df.test_recordtime)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(f'analysis_sets/{year}_{month}_trimmed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_df\n",
    "del final_df\n",
    "del defs_df\n",
    "del dfs\n",
    "del defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "\n",
    "keep_cols = ['timestamp', 'market_id', 'sid', 'batl', 'batb', 'batl_v', 'batb_v',\n",
    "       'batl_v_1', 'batb_v_1', 'batl_v_2', 'batb_v_2', 'batl_v_3', 'batb_v_3',\n",
    "       'batl_v_4', 'batb_v_4', 'batl_v_5', 'batb_v_5', 'tot_vol', 'mean_trd']\n",
    "\n",
    "df = df[keep_cols]\n",
    "\n",
    "df['mid'] = (df.batb + df.batl) / 2\n",
    "\n",
    "price_cols = ['batl', 'batb', 'mean_trd', 'mid']\n",
    "for c in price_cols:\n",
    "    df[f'{c}_ticks'] = df[c].apply(dollars_to_ticks)\n",
    "\n",
    "df['spread'] = df.batl_ticks - df.batb_ticks\n",
    "\n",
    "df['diff'] = df.groupby(['market_id', 'sid']).mid_ticks.diff().cumsum()\n",
    "\n",
    "# temp = df[df.spread==1]\n",
    "df['diff_ticks'] = df.groupby(['market_id', 'sid']).mid_ticks.diff()\n",
    "df['diff_ticks'] = df.groupby(['market_id', 'sid']).diff_ticks.cumsum()\n",
    "\n",
    "df['trade_cnt'] = 1\n",
    "df['trade_cnt'] = df.groupby(['market_id', 'sid']).trade_cnt.cumsum()\n",
    "\n",
    "vals = {}\n",
    "idxs = {}\n",
    "for sid in df.sid.unique():\n",
    "    vals[sid] = df[df.sid==sid].mid_ticks.values\n",
    "    idxs[sid] = df[df.sid==sid].index.values\n",
    "\n",
    "def find_pos(row):\n",
    "    val = row.mid_ticks + 5\n",
    "    idx = np.argwhere(idxs[row.sid] == row.inc_idx).flatten()[0]\n",
    "    val = np.argmax(vals[row.sid][idx:] >= val)\n",
    "    return val\n",
    "\n",
    "def find_neg(row):\n",
    "    val = row.mid_ticks - 5\n",
    "    idx = np.argwhere(idxs[row.sid] == row.inc_idx).flatten()[0]\n",
    "    val = np.argmax(vals[row.sid][idx:] <= val)\n",
    "    return val\n",
    "\n",
    "df['inc_idx'] = df.index\n",
    "\n",
    "df['pos_idx'] = df.apply(find_pos, axis=1)\n",
    "\n",
    "df['neg_idx'] = df.apply(find_neg, axis=1)\n",
    "\n",
    "df['label'] = df.pos_idx < df.neg_idx\n",
    "\n",
    "for x in range(1, 50):\n",
    "    df[f'ticks_{x}'] = df.mid_ticks - df.groupby(['market_id', 'sid']).mid_ticks.shift(x)\n",
    "\n",
    "df['ticks_from_mean'] = df.mid_ticks - df.mean_trd_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['batl_v', 'batb_v',\n",
    "       'batl_v_1', 'batb_v_1', 'batl_v_2', 'batb_v_2', 'batl_v_3', 'batb_v_3',\n",
    "       'batl_v_4', 'batb_v_4', 'batl_v_5', 'batb_v_5', 'ticks_from_mean',\n",
    "       'spread', 'ticks_1', 'ticks_2', 'ticks_3', 'ticks_4',\n",
    "       'ticks_5', 'ticks_6', 'ticks_7', 'ticks_8', 'ticks_9', 'ticks_10',\n",
    "       'ticks_11', 'ticks_12', 'ticks_13', 'ticks_14', 'ticks_15', 'ticks_16',\n",
    "       'ticks_17', 'ticks_18', 'ticks_19', 'ticks_20', 'ticks_21', 'ticks_22',\n",
    "       'ticks_23', 'ticks_24', 'ticks_25', 'ticks_26', 'ticks_27', 'ticks_28',\n",
    "       'ticks_29', 'ticks_30', 'ticks_31', 'ticks_32', 'ticks_33', 'ticks_34',\n",
    "       'ticks_35', 'ticks_36', 'ticks_37', 'ticks_38', 'ticks_39', 'ticks_40',\n",
    "       'ticks_41', 'ticks_42', 'ticks_43', 'ticks_44', 'ticks_45', 'ticks_46',\n",
    "       'ticks_47', 'ticks_48', 'ticks_49']\n",
    "\n",
    "y_name = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_df = df[feature_cols + [y_name]].dropna()\n",
    "pass_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['FN'] = f'{year}_{month}.csv'\n",
    "pass_df.to_csv('./test.csv')\n",
    "!gsutil cp ./test.csv gs://temp_h2o/$FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "betfair",
   "language": "python",
   "name": "betfair"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
